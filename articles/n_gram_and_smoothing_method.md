# n-gram模型及其平滑方法

# 一、定义

n-gram模型是用马尔可夫假设简化的语言模型。

原始的统计语言模型要算无数种组合可能出现的概率。引入马尔科夫假设可以简化这个模型，即一个句子中的相邻的n个词有相关，从而提出n-gram模型。其中n常称为语言模型的阶数（order)，它限制了一个句子中词与词之间具有相关性的范围。接下来，依次介绍常见阶数语言模型。

- n=1时，unigram（1-gram)：最直观的想法，认为各个词不相关，一个句子的出现概率等于每个词出现概率的乘积：

$$
P(W)=P(w_1)×P(w_2)×P(w_3)×...×P(w_n)
$$

但这实际上违背了相邻词具有相关性这个基本条件，一般效果不好。比如“New York”在文本中出现的概率肯定比“Old York”出现的多。

- n=2时，bigram(2-gram)：意识到词之间的联系，认为邻的2个词相关:

$$
P(W)=P(w_1)×P(w_2|w_1)×P(w_3|w_2)×...×P(w_n|w_{n-1})
$$

- trigram(3-gram)认为3个之间相关:

$$
P(W)=P(w_1)×P(w_2|w_1)×P(w_3|w_1,w_2)×...×P(w_n|w_{n-1},w_{n-2})
$$

以此类推。实际情况中，往往n越大，计算量指数增长，但是模型性能不一定指数增长。所以通常最多n取4或5**。**

# 二、平滑方法