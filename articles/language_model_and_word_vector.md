# 语言模型与词向量

# 一、语言模型

## 1. 语言模型定义

统计语言模型是指通过计算一个句子的联合概率，来判断该句是否符合自然语言规律的概率模型。用$W=w_1^T:=(w_1,w_2,w_3,...,w_T)$表示一个有$T$个词的句子，$p(W)$表示此句子按照$(w_1,w_2,w_3,...,w_T)$这样的顺序出现的联合概率，即：
$$
p(W)=p(w_1,w_2,w_3,...,w_T)
$$
根据[贝叶斯定理](math/贝叶斯定理.md)，上述联合概率可以通过链式贝叶斯定理计算得到：
$$
p(W)=p(w_1^T)=p(w_1)·p(w_2|w_1)·p(w_3|w_1^2)···p(w_T|w_1^{T-1})
$$
上式中，$w_i$表示句子中的一个字，$w_i^j$表示$W$中从$i$开始到$j$结束的一个子句。

举个简单的例子，“今天天气真好”的联合概率密度$p(今天天气真好)$可以通过下式计算：
$$
p(今天天气真好)=p(今)·p(天|今)·p(天|今天)·p(气|今天天)·p(真|今天天气)p(好|今天天气真)
$$
上式中，每一个条件概率都是语言模型的一个参数。只要计算出上述参数，就可以计算得到一个句子的概率。

可以看出，一个长度为$T$的句子，需要计算$T$个参数。

一个语言模型需要考虑语料库中所有可能存在的句子及其条件概率，假设语料库中词汇量为$N$，任意一个长度为$T$的句子就有$N^T$种可能，每个句子的参数为$T$，则得到一个语言模型就需要$TN^T$个参数。

## 2. 计算语言模型常见方法

上面说到，计算得到语言模型的参数（即条件概率），就可以得到语言模型。

常见的计算语言模型参数的方法有：

- [n-gram语言模型](.\n_gram_and_smoothing_method.md)
- 神经网络方法
- 决策树
- 最大熵模型
- 最大熵马尔科夫模型
- 条件随机场
- ......

### （1）n-gram语言模型

n-gram模型是用马尔可夫假设简化的语言模型。

原始的统计语言模型要算无数种组合可能出现的概率。引入马尔科夫假设可以简化这个模型，即一个句子中的相邻的n个词有相关，从而提出n-gram模型。其中n常称为语言模型的阶数（order)，它限制了一个句子中词与词之间具有相关性的范围。

[n-gram语言模型](.\n_gram_and_smoothing_method.md)

### （2）神经网络方法



# 二、词向量

## 1. 词向量是神经网络方法中对自然语言的一种数学表达

神经网络语言模型和n-gram语言模型思路不同。统计语言模型的目的是计算一个句子出现的概率。n-gram通过明确地计算得到条件概率，从而得到整个句子的出现概率，可以看成一种自底而上的计算方法。

神经网络是一种自顶而下的方法，在计算概率的任务中，先设定一个关于概率的目标函数，再通过迭代的方式对神经网络参数进行优化，最终求得一组最优参数，就可以利用此神经网络进行概率预测。

神经网络的目标函数是预测概率的最大似然函数：







## 2. 神经网络方法分类















